# Dao – AI Agents Guide

Practical documentation for Dao’s AI layer: the agents, their endpoints, and how they interact with tasks, notes, and the board. Use this to extend or debug AI behavior without breaking the flow-first experience.

## 0) Purpose & scope

- Assistive, not intrusive: AI suggests; users decide.
- Typed outputs: Prefer schemas via Vercel AI SDK to minimize surprises.
- Keep core creation uncluttered: AI surfaces live in dedicated flows or subtle micro‑actions.

Code map
- Agent types and DTOs: `src/lib/ai/types.ts`
- Agents: `src/lib/ai/agents/*`
- AI routes: `src/app/api/ai/**`
- Task micro‑actions: `src/app/api/ai/cards/[taskId]/*`
- Agent logging: `src/server/db/agentRuns.ts` + Prisma models

---

## 1) Conventions

### 1.1 Context & DTOs

- `AgentContext` holds raw inputs (e.g., `brainDumpText`) and outputs (`generatedTasks`, `gemAwards`, etc.).
- `TaskDTO` mirrors a subset of Prisma `Task` fields for AI use: `title`, `descriptionMarkdown?`, `priority?`, `tags?`, `estimatedPomodoros?`, `status?`, `autoGenerated?`.

### 1.2 Models & logging

- Every long‑running AI call should create an `AgentRun` and append `AIEvent`s for metrics or outputs.
- Persist only validated fields; keep raw model output in `debug` fields or `AgentOutput` when useful.

### 1.3 Streaming

- Use `streamObject` for predictable, UI‑friendly streams (e.g., plans)
- Use `generateText`/`generateObject` for non‑streamed transformations (classification/enrichment/suggestion)

---

## 2) Agent inventory

### 2.1 Initial rollout scope

We keep the AI surface minimal for snappy UX:
- Categorize (topics only)
- Enrich
- Summary

### 2.3 Card micro‑actions

These operate on a specific Task and persist AI results back to the Task.

- Categorize (topics only)
  - Endpoint: `POST /api/ai/cards/[taskId]/classify`
  - Agent: `src/lib/ai/agents/classifierAgent.ts`
  - Output: `{ topics[], primaryTopic, confidence }`
  - Side‑effects: updates `topics[]`, `primaryTopic`, `aiState=CLASSIFIED`.

#### Task Topics (for visualization & reporting)

- Canonical list lives in `src/lib/ai/taxonomy.ts` (`TASK_TOPICS`). Classifier chooses up to 3 topics and one `primaryTopic`.
- Topics: Planning & Strategy, Product Management, Coding & Development, DevOps & Infra, Bugfix & Debugging, QA & Testing, Design & UX, Writing & Documentation, Data & Analytics, Research & Learning, Communication & Meetings, Customer Support, Sales & Outreach, Marketing & Growth, Finance & Admin, Legal & Compliance, Operations & Maintenance, Security & Privacy, Personal & Wellness, Home & Errands, Career & Growth, General.
- Schema fields persisted on Task: `topics: string[]`, `primaryTopic?: string`.

Smart strategy to keep this useful (not busywork):
- Use topics only where they unlock value: weekly report breakdowns, trend charts, focus/energy alignment, and "what’s creeping in" alerts (e.g., too many Admin tasks).
- Keep it subtle in the UI (chips/filters). Avoid mandatory inputs—topics are auto‑inferred and editable.
- Drive nudges: “You’ve done lots of Ops this week; want to schedule one deep Coding block tomorrow?”

- Enrich
  - Endpoint: `POST /api/ai/cards/[taskId]/enrich`
  - Agent: `src/lib/ai/agents/cardEnrichmentAgent.ts`
  - Output: `{ descriptionMarkdown, subtasks: [{ title, estimateMin }], kind, confidence }`
  - Side‑effects: updates description, `aiSubtasks`, `aiSuggestedEstimateMin`, `estimatedPomodoros` (derived), `aiState=ENRICHED`.

  (Suggest/auto‑move disabled.)

### 2.4 Notes helpers (learning)

- Summary: `POST /api/ai/notes/[noteId]/summary` – generates real summaries and bullets via the AI model.
  (Quiz removed.)

### 2.5 Gamification lore (optional)

- Agent: `src/lib/ai/agents/gamifyAgent.ts` can generate 1–2 line lore when stones are awarded.
- Deterministic core lives in `src/lib/gamification/engine.ts` and `/api/gamify/*` endpoints.

---

## 3) Error handling & fallbacks

- All endpoints return friendly fallbacks when the model call fails (e.g., keep current column/priority, add a reasonable estimate, minimal description).
- Never block the user: when in doubt, keep original data and surface a suggestion instead of auto‑editing.

---

## 4) Observability

- Start and finish each agent run via `logAgentRunStart`/`logAgentRunFinish` with duration and (sanitized) outputs.
- For UI streams, prefer server‑side logging (no PII) plus client‑side analytics events (`useProductAnalytics`).

---

## 5) Extending the system

- Define a Zod schema first; choose streaming vs non‑streaming intentionally.
- Keep outputs minimal and actionable; persist only validated fields.
- Add a dedicated API route under `app/api/ai/**` rather than overloading existing ones.
- Update the Task’s `aiState` lifecycle (`RAW → CLASSIFIED → ENRICHED → SUGGESTED → COMPLETED`) as appropriate.
- Add a short, discoverable UI affordance; avoid interruptive modals.

---

## 6) Appendix: Types

- `TaskDTO`: title, descriptionMarkdown?, priority?, status?, estimatedPomodoros?, tags?, autoGenerated?
- `AgentContext`: userId, brainDumpText?, quickTodoText?, noteMarkdown?, boardId?, generatedTasks?, enrichedTasks?, flashcards?, quizQuestions?, gemAwards?, meta?
- `AgentResult`: `{ context, debug? }`
